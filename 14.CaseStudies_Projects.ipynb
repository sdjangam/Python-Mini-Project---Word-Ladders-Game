{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gmanish\\AppData\\Local\\Continuum\\Anaconda\\envs\\py36\\lib\\site-packages\\urllib3\\connectionpool.py:852: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4862966"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib3\n",
    "http = urllib3.PoolManager()\n",
    "r = http.request('GET', \n",
    "\"https://raw.githubusercontent.com/dwyl/english-words/master/words.txt\", \n",
    "preload_content=False)\n",
    "with open(\"data/words.txt\", 'wb') as out:\n",
    "    data = r.read()\n",
    "    out.write(data)\n",
    "r.release_conn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_list = open('data/words.txt').readlines()\n",
    "word_list = map(str.strip, word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1017"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = [word for word in word_list if len(word) == 3]\n",
    "word_list = [word for word in word_list if word[0].islower()]\n",
    "word_list = [word for word in word_list if word.isalpha()]\n",
    "word_list = list(map(str.lower, word_list))\n",
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<U3')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "word_list = np.asarray(word_list)\n",
    "word_list.dtype #unicode\n",
    "word_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1017, 12)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1017, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_bytes = np.ndarray((word_list.size, \n",
    "word_list.itemsize), dtype='uint8',\n",
    "buffer=word_list.data)\n",
    "# each unicode character is four bytes long. \n",
    "# We only need first byte\n",
    "# we know that there are 3 characters per word\n",
    "word_bytes.shape\n",
    "word_bytes = word_bytes[:, ::word_list.itemsize//3]\n",
    "word_bytes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aah', 'aal', 'abb', 'abd'], \n",
       "      dtype='<U3')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 97,  97, 104],\n",
       "       [ 97,  97, 108],\n",
       "       [ 97,  98,  98],\n",
       "       [ 97,  98, 100]], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(516636,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "516636.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list[0:4]\n",
    "word_bytes[0:4]\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.sparse import csr_matrix\n",
    "#pdist: Pairwise distances bet. obs. in n-D space\n",
    "hamming_dist = pdist(word_bytes, metric='hamming')\n",
    "hamming_dist.shape\n",
    "(1017*1017-1017)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.33333333,  0.66666667,  0.66666667],\n",
       "       [ 0.33333333,  0.        ,  0.66666667,  0.66666667],\n",
       "       [ 0.66666667,  0.66666667,  0.        ,  0.33333333],\n",
       "       [ 0.66666667,  0.66666667,  0.33333333,  0.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1017, 1017)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[False,  True, False, False],\n",
       "       [ True, False, False, False],\n",
       "       [False, False, False,  True],\n",
       "       [False, False,  True, False]], dtype=bool)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Squareform: Converts a vector-form distance vector \n",
    "# to a square-form distance matrix\n",
    "squareform(hamming_dist)[0:4,0:4]\n",
    "# there are three characters in each word\n",
    "mat=squareform(hamming_dist < 1.5 / 3)\n",
    "mat.shape\n",
    "mat[0:4,0:4]\n",
    "graph = csr_matrix(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1 = word_list.searchsorted('and')\n",
    "i2 = word_list.searchsorted('dog')\n",
    "word_list[i1]\n",
    "word_list[i2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse.csgraph import dijkstra\n",
    "distances, predecessors = dijkstra(graph, \n",
    "indices=i1,return_predecessors=True)\n",
    "print(distances[i2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'aud', 'mud', 'mug', 'dug', 'dog']\n"
     ]
    }
   ],
   "source": [
    "path = []\n",
    "i = i2\n",
    "while i != i1:\n",
    "    path.append(word_list[i])\n",
    "    i = predecessors[i]\n",
    "path.append(word_list[i1])\n",
    "print(path[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1017,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse.csgraph import connected_components\n",
    "N_components, component_list = connected_components(graph)\n",
    "print(N_components)\n",
    "component_list.shape\n",
    "component_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1009, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.sum(component_list == i) for i in range(N_components)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['bcf'], ['bdl'], ['epi'], ['mmf'], ['sml'], ['wjc'], ['xcl'], ['xyz']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(word_list[np.where(component_list == i)]) for i in range(1, N_components)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.0\n"
     ]
    }
   ],
   "source": [
    "distances, predecessors = dijkstra(graph, return_predecessors=True)\n",
    "max_distance = np.max(distances[~np.isinf(distances)])\n",
    "print(max_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dlr', 'hmm'),\n",
       " ('dlr', 'kmc'),\n",
       " ('hmm', 'dlr'),\n",
       " ('hmm', 'lbf'),\n",
       " ('hmm', 'rfz'),\n",
       " ('hmm', 'tfr'),\n",
       " ('kmc', 'dlr'),\n",
       " ('kmc', 'tfr'),\n",
       " ('lbf', 'hmm'),\n",
       " ('rfz', 'hmm'),\n",
       " ('tfr', 'hmm'),\n",
       " ('tfr', 'kmc')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1, i2 = np.where(distances == max_distance)\n",
    "list(zip(word_list[i1], word_list[i2]))\n",
    "type(i1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dlr', 'tlr', 'tlo', 'too', 'tot', 'tgt', 'ugt', 'ust', 'usu', 'umu', 'umm', 'hmm']\n",
      "['dlr', 'tlr', 'tlo', 'blo', 'blk', 'ilk', 'ick', 'ich', 'iph', 'kph', 'kpc', 'kmc']\n",
      "['hmm', 'umm', 'umu', 'usu', 'ush', 'bsh', 'boh', 'boo', 'blo', 'tlo', 'tlr', 'dlr']\n",
      "['hmm', 'umm', 'umu', 'usu', 'ust', 'ast', 'abt', 'abl', 'dbl', 'dbw', 'lbw', 'lbf']\n",
      "['hmm', 'umm', 'ump', 'unp', 'uns', 'uhs', 'chs', 'cfs', 'cfm', 'sfm', 'sfz', 'rfz']\n",
      "['hmm', 'umm', 'umu', 'usu', 'ush', 'bsh', 'boh', 'boo', 'blo', 'tlo', 'tlr', 'tfr']\n",
      "['kmc', 'kpc', 'kph', 'iph', 'ich', 'ick', 'ilk', 'blk', 'blo', 'tlo', 'tlr', 'dlr']\n",
      "['kmc', 'kpc', 'kph', 'iph', 'ich', 'ick', 'ilk', 'blk', 'blo', 'tlo', 'tlr', 'tfr']\n",
      "['lbf', 'lbw', 'dbw', 'daw', 'baw', 'bah', 'bsh', 'ush', 'usu', 'umu', 'umm', 'hmm']\n",
      "['rfz', 'rfb', 'rub', 'rud', 'rnd', 'end', 'enc', 'unc', 'unp', 'ump', 'umm', 'hmm']\n",
      "['tfr', 'tlr', 'tlo', 'too', 'tot', 'tgt', 'ugt', 'ust', 'usu', 'umu', 'umm', 'hmm']\n",
      "['tfr', 'tlr', 'tlo', 'blo', 'blk', 'ilk', 'ick', 'ich', 'iph', 'kph', 'kpc', 'kmc']\n"
     ]
    }
   ],
   "source": [
    "for j,i in zip(i1,i2):\n",
    "    path = []\n",
    "    while i != j:\n",
    "        path.append(word_list[i])\n",
    "        i = predecessors[j,i]\n",
    "    path.append(word_list[j])\n",
    "    print(path[::-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
